{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JZiTj1xoaBR6"
   },
   "source": [
    "# 09 - RNN Sentiment Classification\n",
    "Prepared by Jan Christian Blaise Cruz\n",
    "\n",
    "DLSU Machine Learning Group\n",
    "\n",
    "We'll continue our demos of recurrent neural networks by using them in another task: sentiment classification. We'll first show how to use LSTMs for sentiment classification, apply some techniques to improve performance, and use all of the techniques in our toolbox so far to make a robust classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NIeQRLltpiXw"
   },
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "nz_1G-0XtYnT",
    "outputId": "8e8282a6-dadc-431d-8429-e958aa90fd2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Aug 25 11:19:17 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   38C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RRzkU4j6aV03"
   },
   "source": [
    "We'll download the iMDB sentiment dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kim8Wh2WtlaL"
   },
   "outputs": [],
   "source": [
    "!wget https://s3.us-east-2.amazonaws.com/blaisecruz.com/datasets/imdb/imdb.zip\n",
    "!unzip imdb.zip && rm imdb.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ytcj_zKaZw7"
   },
   "source": [
    "Standard imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xPCn0d6tt7kB"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import spacy\n",
    "en = spacy.load('en')\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NgcipVFe5rmL"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ol7SW1gmaczg"
   },
   "source": [
    "Load and shuffle the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YAJSBDSwuPPh"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('imdb/train.csv').sample(frac=1.0, random_state=42)\n",
    "text, labels = list(df['text']), list(df['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Va6KQnyjaegs"
   },
   "source": [
    "Here's the first example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "colab_type": "code",
    "id": "mKcZ-vQsubVQ",
    "outputId": "d27fe88d-d938-4edd-e52a-904be6312da3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Great little thriller. I was expecting some type of silly horror movie but what I got was tight short thriller that waste none of our time. Mostof these movies we have to get into the back characters stories so we will either feel sympathy for them or hatred when people start getting killed. o such foolishness here. Yes you see a few characters but they really only interact with the principals. Such as the husband wife at the motel whose room was canceled. We saw them so we could just how efficient the Lisa character was and how inefficient the new Hotel clerk was. We see the little girl simply because she will have a very small but important role later in the movie when all heck breaks loose. THe Flight Atrendants because we need on in particular to move the plot ahead. The bad guy in particular needs her in the beginning of the flight. The rude guy in the airport was important to the movie too. The only 2 characters that were just 5 liners with no use to the plot were the two young guys on the plane. THat was clever because I thought they would have something to do with plot. From the first scene to the last the woman character a young hotel executive named Lisa is in charge. Even when Jackson shows his true colors she doesn't panic. She thinks what she can do to stall time. Any other movie the smart executive women would be acting like idiots. But not this one. It was a very short movie and I was waiting for the usual plot devices to kick in because the movie seemed to be coming to its conclusion fast. Thankfuly none of them were used. The new hotel clerk did not do the usual called and told her what to do, which is panic drop the phone and run out of the hotel without saying anything, or question your boss and tell her she had to much to drink and just dismiss her. Was Craven should do more of these types of movies. Also one last comment. Brian Cox is in the movie but I had not one clue who he was. I had to come over here to see that he is Lisa's father. He is completely unrecognizable.\""
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KzVH2op-afyT"
   },
   "source": [
    "We'll code up a tokenization function using Spacy. You may use your own here, but for the purpose of demonstration, we'll use a pretrained tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mub2lwQqueWp"
   },
   "outputs": [],
   "source": [
    "def tokenize(t): return [str(token) for token in en(t)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rkMVRexfalXS"
   },
   "source": [
    "This next cell takes about 20 minutes to process, so to save time, we'll load a pre-tokenized version of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fhHKM93cuogJ"
   },
   "outputs": [],
   "source": [
    "#text = [tokenize(t) for t in tqdm(text)]\n",
    "#with open('tokenized.pt', 'wb') as f:\n",
    "#    torch.save([text], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ixjXsE_jast3"
   },
   "source": [
    "Download the tokenized version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zxEr5jzyCM4O"
   },
   "outputs": [],
   "source": [
    "#!wget https://s3.us-east-2.amazonaws.com/blaisecruz.com/datasets/imdb/tokenized.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V8c4k23VauNw"
   },
   "source": [
    "Then load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IzGCv2mdvyJD"
   },
   "outputs": [],
   "source": [
    "with open('tokenized.pt', 'rb') as f:\n",
    "    text = torch.load(f)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vPYcLxoCavNn"
   },
   "source": [
    "Here's the first review in tokenized form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "zAge5Gw6wAyj",
    "outputId": "c210815e-ad44-44b9-8098-9263345e10b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Great', 'little', 'thriller', '.', 'I', 'was', 'expecting', 'some', 'type', 'of', 'silly', 'horror', 'movie', 'but', 'what', 'I', 'got', 'was', 'tight', 'short', 'thriller', 'that', 'waste', 'none', 'of', 'our', 'time', '.', 'Mostof', 'these', 'movies', 'we', 'have', 'to', 'get', 'into', 'the', 'back', 'characters', 'stories', 'so', 'we', 'will', 'either', 'feel', 'sympathy', 'for', 'them', 'or', 'hatred', 'when', 'people', 'start', 'getting', 'killed', '.', 'o', 'such', 'foolishness', 'here', '.', 'Yes', 'you', 'see', 'a', 'few', 'characters', 'but', 'they', 'really', 'only', 'interact', 'with', 'the', 'principals', '.', 'Such', 'as', 'the', 'husband', 'wife', 'at', 'the', 'motel', 'whose', 'room', 'was', 'canceled', '.', 'We', 'saw', 'them', 'so', 'we', 'could', 'just', 'how', 'efficient', 'the', 'Lisa', 'character', 'was', 'and', 'how', 'inefficient', 'the', 'new', 'Hotel', 'clerk', 'was', '.', 'We', 'see', 'the', 'little', 'girl', 'simply', 'because', 'she', 'will', 'have', 'a', 'very', 'small', 'but', 'important', 'role', 'later', 'in', 'the', 'movie', 'when', 'all', 'heck', 'breaks', 'loose', '.', 'THe', 'Flight', 'Atrendants', 'because', 'we', 'need', 'on', 'in', 'particular', 'to', 'move', 'the', 'plot', 'ahead', '.', 'The', 'bad', 'guy', 'in', 'particular', 'needs', 'her', 'in', 'the', 'beginning', 'of', 'the', 'flight', '.', 'The', 'rude', 'guy', 'in', 'the', 'airport', 'was', 'important', 'to', 'the', 'movie', 'too', '.', 'The', 'only', '2', 'characters', 'that', 'were', 'just', '5', 'liners', 'with', 'no', 'use', 'to', 'the', 'plot', 'were', 'the', 'two', 'young', 'guys', 'on', 'the', 'plane', '.', 'THat', 'was', 'clever', 'because', 'I', 'thought', 'they', 'would', 'have', 'something', 'to', 'do', 'with', 'plot', '.', 'From', 'the', 'first', 'scene', 'to', 'the', 'last', 'the', 'woman', 'character', 'a', 'young', 'hotel', 'executive', 'named', 'Lisa', 'is', 'in', 'charge', '.', 'Even', 'when', 'Jackson', 'shows', 'his', 'true', 'colors', 'she', 'does', \"n't\", 'panic', '.', 'She', 'thinks', 'what', 'she', 'can', 'do', 'to', 'stall', 'time', '.', 'Any', 'other', 'movie', 'the', 'smart', 'executive', 'women', 'would', 'be', 'acting', 'like', 'idiots', '.', 'But', 'not', 'this', 'one', '.', 'It', 'was', 'a', 'very', 'short', 'movie', 'and', 'I', 'was', 'waiting', 'for', 'the', 'usual', 'plot', 'devices', 'to', 'kick', 'in', 'because', 'the', 'movie', 'seemed', 'to', 'be', 'coming', 'to', 'its', 'conclusion', 'fast', '.', 'Thankfuly', 'none', 'of', 'them', 'were', 'used', '.', 'The', 'new', 'hotel', 'clerk', 'did', 'not', 'do', 'the', 'usual', 'called', 'and', 'told', 'her', 'what', 'to', 'do', ',', 'which', 'is', 'panic', 'drop', 'the', 'phone', 'and', 'run', 'out', 'of', 'the', 'hotel', 'without', 'saying', 'anything', ',', 'or', 'question', 'your', 'boss', 'and', 'tell', 'her', 'she', 'had', 'to', 'much', 'to', 'drink', 'and', 'just', 'dismiss', 'her', '.', 'Was', 'Craven', 'should', 'do', 'more', 'of', 'these', 'types', 'of', 'movies', '.', 'Also', 'one', 'last', 'comment', '.', 'Brian', 'Cox', 'is', 'in', 'the', 'movie', 'but', 'I', 'had', 'not', 'one', 'clue', 'who', 'he', 'was', '.', 'I', 'had', 'to', 'come', 'over', 'here', 'to', 'see', 'that', 'he', 'is', 'Lisa', \"'s\", 'father', '.', 'He', 'is', 'completely', 'unrecognizable', '.']\n"
     ]
    }
   ],
   "source": [
    "print(text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CDSP3M3daxT2"
   },
   "source": [
    "We'll remove capitalization to reduce the vocabulary and prevent our weights from being too sparse. To prevent loss of information, we'll add special tokens to denote capitalization instead.\n",
    "\n",
    "We will also trim and pad our sequences to a specific **Maximum Sequence Length** (MSL). Unlike in language modeling, we will actually batch our samples, and they will have to be of same lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eMXddC1ZwPcE"
   },
   "outputs": [],
   "source": [
    "def process(line, msl):\n",
    "    # Process each character\n",
    "    temp = []\n",
    "    for token in line:\n",
    "        if token.isupper():\n",
    "            temp.append('<cap>')\n",
    "        elif token[0].isupper():\n",
    "            temp.append('<maj>')\n",
    "        temp.append(token.lower())\n",
    "    temp.append('<eos>')\n",
    "\n",
    "    # Pad/trim to MSL\n",
    "    temp = temp[:msl]\n",
    "    if len(temp) < msl:\n",
    "        temp += ['<pad>' for _ in range(msl - len(temp))]\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WvxwjHFObGwY"
   },
   "source": [
    "Here's an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "7NQqNCdMweFk",
    "outputId": "cd4cb903-bc06-495e-c99f-1ec37d0e5591"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<maj>', 'great', 'little', 'thriller', '.', '<cap>', 'i', 'was', 'expecting', 'some', 'type', 'of', 'silly', 'horror', 'movie', 'but', 'what', '<cap>', 'i', 'got', 'was', 'tight', 'short', 'thriller', 'that', 'waste', 'none', 'of', 'our', 'time', '.', '<maj>', 'mostof', 'these', 'movies', 'we', 'have', 'to', 'get', 'into', 'the', 'back', 'characters', 'stories', 'so', 'we', 'will', 'either', 'feel', 'sympathy', 'for', 'them', 'or', 'hatred', 'when', 'people', 'start', 'getting', 'killed', '.', 'o', 'such', 'foolishness', 'here', '.', '<maj>', 'yes', 'you', 'see', 'a', 'few', 'characters', 'but', 'they', 'really', 'only', 'interact', 'with', 'the', 'principals', '.', '<maj>', 'such', 'as', 'the', 'husband', 'wife', 'at', 'the', 'motel', 'whose', 'room', 'was', 'canceled', '.', '<maj>', 'we', 'saw', 'them', 'so', 'we', 'could', 'just', 'how', 'efficient', 'the', '<maj>', 'lisa', 'character', 'was', 'and', 'how', 'inefficient', 'the', 'new', '<maj>', 'hotel', 'clerk', 'was', '.', '<maj>', 'we', 'see', 'the', 'little', 'girl', 'simply', 'because', 'she', 'will', 'have', 'a', 'very', 'small', 'but', 'important', 'role', 'later', 'in', 'the', 'movie', 'when', 'all', 'heck', 'breaks', 'loose', '.', '<maj>', 'the', '<maj>', 'flight', '<maj>', 'atrendants', 'because', 'we', 'need', 'on', 'in', 'particular', 'to', 'move', 'the', 'plot', 'ahead', '.', '<maj>', 'the', 'bad', 'guy', 'in', 'particular', 'needs', 'her', 'in', 'the', 'beginning', 'of', 'the', 'flight', '.', '<maj>', 'the', 'rude', 'guy', 'in', 'the', 'airport', 'was', 'important', 'to', 'the', 'movie', 'too', '.', '<maj>', 'the', 'only', '2', 'characters', 'that', 'were', 'just', '5', 'liners', 'with', 'no', 'use', 'to', 'the', 'plot', 'were', 'the', 'two', 'young', 'guys', 'on', 'the', 'plane', '.', '<maj>', 'that', 'was', 'clever', 'because', '<cap>', 'i', 'thought', 'they', 'would', 'have', 'something', 'to', 'do', 'with', 'plot', '.', '<maj>', 'from', 'the', 'first', 'scene', 'to', 'the', 'last', 'the', 'woman', 'character', 'a', 'young', 'hotel', 'executive', 'named', '<maj>', 'lisa', 'is', 'in', 'charge', '.', '<maj>', 'even', 'when', '<maj>', 'jackson', 'shows', 'his', 'true', 'colors', 'she', 'does', \"n't\", 'panic', '.', '<maj>', 'she', 'thinks', 'what', 'she', 'can', 'do', 'to', 'stall', 'time', '.', '<maj>', 'any', 'other', 'movie', 'the', 'smart', 'executive', 'women', 'would', 'be', 'acting', 'like', 'idiots', '.', '<maj>', 'but', 'not', 'this', 'one', '.', '<maj>', 'it', 'was', 'a', 'very', 'short', 'movie', 'and', '<cap>', 'i', 'was', 'waiting', 'for', 'the', 'usual', 'plot', 'devices', 'to', 'kick', 'in', 'because', 'the', 'movie', 'seemed', 'to', 'be', 'coming', 'to', 'its', 'conclusion', 'fast', '.', '<maj>', 'thankfuly', 'none', 'of', 'them', 'were', 'used', '.', '<maj>', 'the', 'new', 'hotel', 'clerk', 'did', 'not', 'do', 'the', 'usual', 'called', 'and', 'told', 'her', 'what', 'to', 'do', ',', 'which', 'is', 'panic', 'drop', 'the', 'phone', 'and', 'run', 'out', 'of', 'the', 'hotel', 'without', 'saying', 'anything', ',', 'or', 'question', 'your', 'boss', 'and', 'tell', 'her', 'she', 'had', 'to', 'much', 'to', 'drink', 'and', 'just', 'dismiss', 'her', '.', '<maj>', 'was', '<maj>', 'craven', 'should', 'do', 'more', 'of', 'these', 'types', 'of', 'movies', '.', '<maj>', 'also', 'one', 'last', 'comment', '.', '<maj>', 'brian', '<maj>', 'cox', 'is', 'in', 'the', 'movie', 'but', '<cap>', 'i', 'had', 'not', 'one', 'clue', 'who', 'he', 'was', '.', '<cap>', 'i', 'had', 'to', 'come', 'over', 'here', 'to', 'see', 'that', 'he', 'is', '<maj>', 'lisa', \"'s\", 'father', '.', '<maj>', 'he', 'is', 'completely', 'unrecognizable', '.', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "print(process(text[0], msl=512))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7aehACHFbIOr"
   },
   "source": [
    "We'll limit the length of the reviews to the median length of the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vRjH0CgRwsvE",
    "outputId": "f2e74594-97bc-4081-94cb-40ac8f2272ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n"
     ]
    }
   ],
   "source": [
    "med_msl = int(np.median([len(line) for line in text]))\n",
    "print(med_msl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R7CoXaO7bMOO"
   },
   "source": [
    "Process the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9qwEDmwVxKCH",
    "outputId": "afbdacdc-776b-41b6-c661-51fbe25854d0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:02<00:00, 11654.02it/s]\n"
     ]
    }
   ],
   "source": [
    "text = [process(line, msl=med_msl) for line in tqdm(text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UAWccGzGbNTV"
   },
   "source": [
    "Then split in to training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b3PpJ-YFxYrm"
   },
   "outputs": [],
   "source": [
    "tr_sz = int(len(text) * 0.7) \n",
    "\n",
    "X_train, y_train = text[:tr_sz], labels[:tr_sz]\n",
    "X_valid, y_valid = text[tr_sz:], labels[tr_sz:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2KwisZvobPCy"
   },
   "source": [
    "Here's the sizes of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "R4rsvjWZxnVI",
    "outputId": "66d9dfda-cd0e-451d-dea8-fee6947540dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17500, 7500)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qx3NoIuGbQXx"
   },
   "source": [
    "Next, we'll build a vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ebe0KiB2x1-o"
   },
   "outputs": [],
   "source": [
    "idx2word = ['<unk>', '<pad>', '<maj>', '<cap>', '<eos>']\n",
    "for line in X_train: idx2word.extend(line)\n",
    "vocab_set = set(idx2word)\n",
    "idx2word = list(vocab_set)\n",
    "\n",
    "word2idx = {idx2word[i]: i for i in range(len(idx2word))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-DDNf16YbSWl"
   },
   "source": [
    "Check the number of tokens in the vocab set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lKbpoG4pyEoL",
    "outputId": "22ac65af-1dad-4e80-d49c-844ccdfcbaa7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56108"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2NKPfebRbUum"
   },
   "source": [
    "Then convert all tokens in the validation set that aren't present in the vocabulary into unknown tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pTWHZLwDyTRs",
    "outputId": "0515d7e3-7afb-4eab-ba6a-508a0c5ba39d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7500/7500 [00:00<00:00, 35039.20it/s]\n"
     ]
    }
   ],
   "source": [
    "X_valid = [[token if token in vocab_set else '<unk>' for token in line] for line in tqdm(X_valid)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uK0fefrqbaYx"
   },
   "source": [
    "Here's an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "55Nq0u2RvU2E",
    "outputId": "7f1096cc-e0bf-4f5d-f5f7-c40c0f41a342"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<maj>', 'bonanza', '\"', ',', '<cap>', 'in', '<cap>', 'color', '!', '!', '!', '<maj>', 'this', '<unk>', 'western', 'evokes', 'an', '<maj>', 'american', 'tradition', 'which', 'accompanies', 'the', '<unk>', 'of', 'the', 'typical', '<cap>', 'u.s.', 'household', 'during', 'the', 'era', 'in', 'which', 'it', 'was', 'viewed', '..', '<maj>', 'the', 'breathtaking', 'cinematography', 'of', '<maj>', 'lake', '<maj>', 'tahoe', 'symbolized', 'an', 'infinite', 'prosperity', 'of', 'the', 'emerging', '<maj>', 'american', 'culture', '!', '!', '<maj>', 'western', '<maj>', 'movies', 'were', 'so', 'popular', 'that', '<maj>', 'western', '<maj>', 'television', '<maj>', 'shows', 'followed', 'suit', '!', '!', '<maj>', 'this', 'was', 'a', 'period', 'in', 'time', 'in', 'our', 'country', 'which', 'yearned', 'for', 'a', 'concise', 'reflection', 'on', 'our', 'own', 'country', \"'s\", 'struggle', 'for', 'survival', '!', '!', '<maj>', 'the', 'end', 'result', 'of', 'the', 'trials', 'and', 'tribulations', 'at', 'the', '<maj>', 'ponderosa', '<maj>', 'ranch', ',', 'as', 'demonstrated', 'in', 'this', 'series', ',', 'sparked', 'a', 'realization', 'that', '<maj>', 'americans', 'are', 'now', 'auspiciously', 'enjoying', 'the', 'fruits', 'of', 'the', '<maj>', 'cartwright', \"'s\", 'painstaking']\n"
     ]
    }
   ],
   "source": [
    "print(X_valid[3][60:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MgWJLwrVbbMp"
   },
   "source": [
    "Next, we'll convert the data into their corresponding indices in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "A12ZdTUivjfg",
    "outputId": "784eab83-4d2a-4ad7-e35a-5a10b83bec4a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17500/17500 [00:00<00:00, 39060.92it/s]\n",
      "100%|██████████| 7500/7500 [00:00<00:00, 46508.29it/s]\n"
     ]
    }
   ],
   "source": [
    "def serialize(line, word2idx):\n",
    "    return [word2idx[token] for token in line]\n",
    "\n",
    "X_train = [serialize(line, word2idx) for line in tqdm(X_train)]\n",
    "X_valid = [serialize(line, word2idx) for line in tqdm(X_valid)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N8k-LNKmbfyp"
   },
   "source": [
    "Turn them into tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vQfg14t516t5"
   },
   "outputs": [],
   "source": [
    "X_train, y_train = torch.LongTensor(X_train), torch.LongTensor(y_train)\n",
    "X_valid, y_valid = torch.LongTensor(X_valid), torch.LongTensor(y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MYkn7hK2bhFt"
   },
   "source": [
    "Here's the final shapes of our training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9AJyl5pJ2SUK",
    "outputId": "d6f5c600-76dc-401d-fb8e-105135fbfa42"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([17500, 204]), torch.Size([7500, 204]))"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AIR3prwubjNx"
   },
   "source": [
    "Lastly, we'll prepare dataloaders with a batch size of 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I3fB1M6C2lMh"
   },
   "outputs": [],
   "source": [
    "bs = 32\n",
    "\n",
    "train_set = data_utils.TensorDataset(X_train, y_train)\n",
    "valid_set = data_utils.TensorDataset(X_valid, y_valid)\n",
    "\n",
    "train_sampler = data_utils.RandomSampler(train_set)\n",
    "train_loader = data_utils.DataLoader(train_set, batch_size=bs, sampler=train_sampler)\n",
    "valid_loader = data_utils.DataLoader(valid_set, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ZVo49VAbly-"
   },
   "source": [
    "Here's the first batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "v2Gq4Pvj26mZ",
    "outputId": "38cf51c1-d5e0-419c-9fa4-7b47dac0e91b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 204])\n",
      "torch.Size([32])\n",
      "tensor([[18249, 28098, 50170,  ..., 22919, 34310, 34312],\n",
      "        [18249, 51860, 51614,  ...,  7469, 11756, 43289],\n",
      "        [ 7469, 45548, 43537,  ..., 51221, 51221, 51221],\n",
      "        ...,\n",
      "        [18249, 28098, 40617,  ..., 51221, 51221, 51221],\n",
      "        [18249, 42748,  4271,  ..., 23061, 18413, 10213],\n",
      "        [ 7469,  9551,  3272,  ..., 51221, 51221, 51221]])\n",
      "tensor([1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
      "        0, 1, 0, 0, 0, 1, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "35Xbk6wx3N3t"
   },
   "source": [
    "# LSTMs for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AWZkaMnbbu3s"
   },
   "source": [
    "To see how everything works together, we'll see them in separate modules first. Let's build an embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0viJItZX3AJS"
   },
   "outputs": [],
   "source": [
    "embeddings = nn.Embedding(len(vocab_set), 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s0YqGwOsbzcz"
   },
   "source": [
    "Embedding our data is straightforward. We'll see three dimensions: batch size, sequence length, and embedding dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mxQOaVUr3SaL",
    "outputId": "43f48952-d227-4f25-dc5a-f4e2b6e408ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 204, 100])\n"
     ]
    }
   ],
   "source": [
    "out = embeddings(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LyD0Nuv9b4Vv"
   },
   "source": [
    "For classification, we have to specify that we're passing data *batch first* to the LSTM. This will make sure we get the right shapes later.\n",
    "\n",
    "The size of the hidden and cell states are (1, batch size, hidden dim). Later on, we'll expound on this, but we'll follow this standard for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-aj8MIHy3WEY"
   },
   "outputs": [],
   "source": [
    "rnn = nn.LSTM(100, 128, batch_first=True)\n",
    "\n",
    "bs, msl = x.shape\n",
    "hidden, cell = torch.zeros(1, bs, 128), torch.zeros(1, bs, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QK6Xiu-YcI1u"
   },
   "source": [
    "We'll pass the embedding inputs and the blank states to our RNN to get updated ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6Mnqso7B3i5D",
    "outputId": "a4621607-45c0-4324-dd29-d2ab091e4946"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 204, 128]) torch.Size([1, 32, 128]) torch.Size([1, 32, 128])\n"
     ]
    }
   ],
   "source": [
    "out, (hidden, cell) = rnn(out, (hidden, cell))\n",
    "\n",
    "print(out.shape, hidden.shape, cell.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m1Ufe9u3cNSe"
   },
   "source": [
    "Now, unlike in language modeling where we want to get the outputs per timestep, we actually want \"aggregated information\" about our entire sentence. The hidden state will suffice for this, specifically the last hidden state, which contains the most information. We'll use that and pass that to a linear projection layer to get our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xl8pEqN74DW7",
    "outputId": "2babd3d1-742d-43b9-85e0-6b76adc0fcae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2])\n"
     ]
    }
   ],
   "source": [
    "fc1 = nn.Linear(128, 2)\n",
    "\n",
    "out = hidden[-1]\n",
    "out = fc1(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o6Fbg_kycb0E"
   },
   "source": [
    "We'll use cross entropy loss as our criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vXz9XRCz4Trs",
    "outputId": "fd4f342e-28bb-4d53-a2ed-abee6b7b009a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6837, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(out, y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yECD8pNIcfmX"
   },
   "source": [
    "Now we'll bring everything together. Remember that we can query the hyperparameters of a layer by accessing its fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "c8sT6VB145tK",
    "outputId": "9fbd4770-99a7-4eea-d50a-d18c38a0238e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.hidden_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6ksidDXlcluA"
   },
   "source": [
    "We'll implement our LSTM classifier like so. \n",
    "\n",
    "Forward propagation is straightforward. We'll produce new hidden states, embed the inputs, pass through the LSTM, get the last hidden state, dropout, then produce outputs. Note that we're reinitializing the hidden states *every iteration* so there's no need to clear the history and detach the tensors like in language modeling.\n",
    "\n",
    "One new thing we'll add here is **weight initialization**. This allows training to be smoother. We'll see how this factors in later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_dr11sID4cCC"
   },
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_sz, embedding_dim, hidden_dim, output_dim, dropout=0.5, initrange=0.1, initialize=True):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_sz, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        if initialize: self.init_weights(initrange)\n",
    "\n",
    "    def init_hidden(self, bs):\n",
    "        weights = next(self.parameters())\n",
    "        hidden_dim = self.rnn.hidden_size\n",
    "\n",
    "        hidden = weights.new_zeros(1, bs, hidden_dim)\n",
    "        cell = weights.new_zeros(1, bs, hidden_dim)\n",
    "        return hidden, cell\n",
    "\n",
    "    def init_weights(self, initrange=0.1):\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc1.bias.data.zero_()\n",
    "        self.fc1.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs, msl = x.shape\n",
    "\n",
    "        hidden, cell = self.init_hidden(bs)\n",
    "        out = self.embedding(x)\n",
    "        out, (hidden, cell) = self.rnn(out, (hidden, cell))\n",
    "        out = self.dropout(hidden[-1])\n",
    "        out = self.fc1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S07kklsVc-ys"
   },
   "source": [
    "Instantiate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vl7C1J1B5RWU"
   },
   "outputs": [],
   "source": [
    "model = LSTMClassifier(vocab_sz=len(vocab_set), \n",
    "                       embedding_dim=100, \n",
    "                       hidden_dim=128, \n",
    "                       output_dim=2, \n",
    "                       dropout=0.5)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZP1UQicLdAUM"
   },
   "source": [
    "Forward prop to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "O2ihE9BR5bCt",
    "outputId": "b459f2f0-078d-4250-91b6-953e7b5a98ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6973, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "out = model(x)\n",
    "loss = criterion(out, y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KcPmRLrFdBok"
   },
   "source": [
    "Let's write an accuracy helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T5VKx9Jg6U59"
   },
   "outputs": [],
   "source": [
    "def accuracy(out, y): \n",
    "    with torch.no_grad():\n",
    "        return torch.mean((out.argmax(1) == y).float()).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HS_6zz4DdDhY"
   },
   "source": [
    "And check our initial test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fOSultRV6hYI",
    "outputId": "22751419-d5fe-49c8-9dc1-a85cf001b85d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4375\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy(out, y)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VnE9omXt5uqO"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "clhlML1LdHm0"
   },
   "source": [
    "We'll write a convenience function to count parameters here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xRDEaEne8MiW"
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwas1xQ_dKy5"
   },
   "source": [
    "Then we'll instantiate our setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bJlZR43e5ouE",
    "outputId": "c985fd27-127f-42d6-d397-7597569a2030"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 5,728,818 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "model = LSTMClassifier(vocab_sz=len(vocab_set), \n",
    "                       embedding_dim=100, \n",
    "                       hidden_dim=128, \n",
    "                       output_dim=2, \n",
    "                       dropout=0.5,\n",
    "                       initialize=False).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "print(\"The model has {:,} trainable parameters\".format(count_parameters(model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1C9OKUoQdNWh"
   },
   "source": [
    "Train for five epochs for illustration. We'll use **gradient clipping**, which prevents our gradients from exploding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "tOjxiujn55Mt",
    "outputId": "b9a5b65b-582b-40d2-c051-83eb18c77d3e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:06<00:00, 84.20it/s]\n",
      "100%|██████████| 235/235 [00:00<00:00, 266.84it/s]\n",
      "  2%|▏         | 9/547 [00:00<00:06, 84.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   1 | Train Loss 0.6948 | Train Acc 0.5134 | Valid Loss 0.6927 | Valid Acc 0.5145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:06<00:00, 84.07it/s]\n",
      "100%|██████████| 235/235 [00:00<00:00, 276.60it/s]\n",
      "  2%|▏         | 9/547 [00:00<00:06, 84.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   2 | Train Loss 0.6884 | Train Acc 0.5349 | Valid Loss 0.6808 | Valid Acc 0.5485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:06<00:00, 84.11it/s]\n",
      "100%|██████████| 235/235 [00:00<00:00, 260.78it/s]\n",
      "  2%|▏         | 9/547 [00:00<00:06, 85.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   3 | Train Loss 0.6627 | Train Acc 0.5829 | Valid Loss 0.6648 | Valid Acc 0.5873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:06<00:00, 83.92it/s]\n",
      "100%|██████████| 235/235 [00:00<00:00, 277.99it/s]\n",
      "  2%|▏         | 9/547 [00:00<00:06, 85.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   4 | Train Loss 0.6120 | Train Acc 0.6674 | Valid Loss 0.6083 | Valid Acc 0.6866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:06<00:00, 83.62it/s]\n",
      "100%|██████████| 235/235 [00:00<00:00, 279.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   5 | Train Loss 0.5416 | Train Acc 0.7519 | Valid Loss 0.5996 | Valid Acc 0.7249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "clip = 1.0\n",
    "\n",
    "for e in range(1, epochs + 1):\n",
    "    train_loss, train_acc = 0, 0\n",
    "    \n",
    "    model.train()\n",
    "    for x, y in tqdm(train_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_acc += accuracy(out, y)\n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc /= len(train_loader)\n",
    "\n",
    "    valid_loss, valid_acc = 0, 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(valid_loader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "            valid_acc += accuracy(out, y)\n",
    "    valid_loss /= len(valid_loader)\n",
    "    valid_acc /= len(valid_loader)\n",
    "\n",
    "    print(\"\\nEpoch {:3} | Train Loss {:.4f} | Train Acc {:.4f} | Valid Loss {:.4f} | Valid Acc {:.4f}\".format(e, train_loss, train_acc, valid_loss, valid_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OqapQ7oidSxx"
   },
   "source": [
    "Now, see the difference when we add in weight initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZxgI6nu9WWLS",
    "outputId": "4fd458d7-06b8-46f4-9efe-e3d63a0c955f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 5,728,818 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "model = LSTMClassifier(vocab_sz=len(vocab_set), \n",
    "                       embedding_dim=100, \n",
    "                       hidden_dim=128, \n",
    "                       output_dim=2, \n",
    "                       dropout=0.5,\n",
    "                       initialize=True).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "print(\"The model has {:,} trainable parameters\".format(count_parameters(model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hgiQZQHgdVZ_"
   },
   "source": [
    "Train with the same settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "G5Npj3NtWWi5",
    "outputId": "b72058c1-7eb9-4fde-c488-7412dcf11e54"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:06<00:00, 84.74it/s]\n",
      "100%|██████████| 235/235 [00:00<00:00, 280.77it/s]\n",
      "  2%|▏         | 9/547 [00:00<00:06, 87.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   1 | Train Loss 0.6932 | Train Acc 0.5059 | Valid Loss 0.6936 | Valid Acc 0.4977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:06<00:00, 84.72it/s]\n",
      "100%|██████████| 235/235 [00:00<00:00, 280.36it/s]\n",
      "  2%|▏         | 9/547 [00:00<00:06, 83.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   2 | Train Loss 0.6649 | Train Acc 0.5832 | Valid Loss 0.5732 | Valid Acc 0.7403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:06<00:00, 84.06it/s]\n",
      "100%|██████████| 235/235 [00:00<00:00, 282.99it/s]\n",
      "  2%|▏         | 9/547 [00:00<00:06, 84.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   3 | Train Loss 0.4349 | Train Acc 0.8247 | Valid Loss 0.4289 | Valid Acc 0.8255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:06<00:00, 83.66it/s]\n",
      "100%|██████████| 235/235 [00:00<00:00, 279.24it/s]\n",
      "  2%|▏         | 9/547 [00:00<00:06, 85.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   4 | Train Loss 0.2867 | Train Acc 0.8980 | Valid Loss 0.3946 | Valid Acc 0.8422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:06<00:00, 83.93it/s]\n",
      "100%|██████████| 235/235 [00:00<00:00, 279.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   5 | Train Loss 0.2043 | Train Acc 0.9360 | Valid Loss 0.4117 | Valid Acc 0.8315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "clip = 1.0\n",
    "\n",
    "for e in range(1, epochs + 1):\n",
    "    train_loss, train_acc = 0, 0\n",
    "    \n",
    "    model.train()\n",
    "    for x, y in tqdm(train_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_acc += accuracy(out, y)\n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc /= len(train_loader)\n",
    "\n",
    "    valid_loss, valid_acc = 0, 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(valid_loader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "            valid_acc += accuracy(out, y)\n",
    "    valid_loss /= len(valid_loader)\n",
    "    valid_acc /= len(valid_loader)\n",
    "\n",
    "    print(\"\\nEpoch {:3} | Train Loss {:.4f} | Train Acc {:.4f} | Valid Loss {:.4f} | Valid Acc {:.4f}\".format(e, train_loss, train_acc, valid_loss, valid_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A0o8lXONdXKi"
   },
   "source": [
    "Good results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "azJzwbpg8zkw"
   },
   "source": [
    "# Bidirectional and Stacked RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RZ5U5Bc3dZzc"
   },
   "source": [
    "This time, let's see how we can stack and extend our LSTMs.\n",
    "\n",
    "Let's get sample data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cu6RGoQeWhF-"
   },
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZBet60aVdfYb"
   },
   "source": [
    "Here, we'll use a bidrectional LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yc9x2oLwWhbu"
   },
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(len(vocab_set), 100)\n",
    "rnn = nn.LSTM(100, 128, batch_first=True, bidirectional=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7XoHpswDdhjR"
   },
   "source": [
    "Notice how the first dimension in our hidden and cell states is now 2. This is because we need two \"containers\" for our hidden and cell states: one for the forward sequence, and one for the backward sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iKxx1z7MWh6a",
    "outputId": "b933184d-a05d-42ef-e228-29d1c36dcc98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 204, 256]) torch.Size([2, 32, 128]) torch.Size([2, 32, 128])\n"
     ]
    }
   ],
   "source": [
    "out = embedding(x)\n",
    "\n",
    "hidden, cell = torch.zeros(2, bs, 128), torch.zeros(2, bs, 128)\n",
    "out, (hidden, cell) = rnn(out, (hidden, cell))\n",
    "\n",
    "print(out.shape, hidden.shape, cell.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1fD3BfkXds3h"
   },
   "source": [
    "Now, instead of using just one hidden state, we'll concatenate both the forward and backward hidden states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IqU61DcNWiTP",
    "outputId": "853721d3-1d88-4bcf-ac46-6d027e4f5ea2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 256])\n"
     ]
    }
   ],
   "source": [
    "out = torch.cat([hidden[-2], hidden[-1]], 1)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dVFqOCOKd14e"
   },
   "source": [
    "And pass that through our projection layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lcKSnCCbWipf",
    "outputId": "15a95d5a-e759-43ca-cfbf-8c0b1eb0a671"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2])\n"
     ]
    }
   ],
   "source": [
    "fc1 = nn.Linear(128 * 2, 2)\n",
    "out = fc1(out)\n",
    "\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xOe8JdTbd4En"
   },
   "source": [
    "Another thing we can do to increase the capacity of our model is to stack multiple RNN layers. We can do this with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pHFMbt40WpxA"
   },
   "outputs": [],
   "source": [
    "rnn = nn.LSTM(100, 128, batch_first=True, num_layers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6PHXQ-hud9xr"
   },
   "source": [
    "Notice that we need \"containers\" equal to the number of RNNs we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NEkaVW62WqDr"
   },
   "outputs": [],
   "source": [
    "hidden, cell = torch.zeros(2, bs, 128), torch.zeros(2, bs, 128)\n",
    "out = embedding(x)\n",
    "out, (hidden, cell) = rnn(out, (hidden, cell))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gK5_dS5ieBcI"
   },
   "source": [
    "Now let's see an example with both stacked and bidirectional LSTMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TnSL3xBBWqb9"
   },
   "outputs": [],
   "source": [
    "rnn = nn.LSTM(100, 128, batch_first=True, num_layers=3, bidirectional=True, dropout=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dUKhBW6EeFh2"
   },
   "source": [
    "The formal shapes of the hidden and cell states will be (directions $\\times$ layers, batch size, hidden dim).\n",
    "\n",
    "Everything else stays the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4v4an8qAWq6U",
    "outputId": "7e0915b8-fbf0-445a-bf35-f08daad3bda2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2])\n"
     ]
    }
   ],
   "source": [
    "# Initialize hyperparameters\n",
    "directions = 2 if rnn.bidirectional else 1\n",
    "n_layers = rnn.num_layers\n",
    "hidden_dim = rnn.hidden_size\n",
    "\n",
    "# Create hidden and cell states\n",
    "hidden = torch.zeros(directions * n_layers, bs, hidden_dim)\n",
    "cell = torch.zeros(directions * n_layers, bs, hidden_dim)\n",
    "\n",
    "# Embedding and RNN\n",
    "x, y = next(iter(train_loader))\n",
    "out = embedding(x)\n",
    "out, (hidden, cell) = rnn(out, (hidden, cell))\n",
    "\n",
    "# Output Layer\n",
    "out = torch.cat([hidden[-2], hidden[-1]], 1) if directions == 2 else hidden[-1]\n",
    "out = fc1(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n0nYSnHAeRbE"
   },
   "source": [
    "Let's put everything together. \n",
    "\n",
    "We'll also introduce recurrent dropout, which is essentially dropout between the outputs of the recurrent layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QsP8x9NFWyDy"
   },
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_sz, embedding_dim, hidden_dim, output_dim, bidirectional=False, n_layers=1, dropout=0.5, recur_dropout=0.3, initrange=0.1, initialize=True):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_sz, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, \n",
    "                           bidirectional=bidirectional, num_layers=n_layers, \n",
    "                           dropout=recur_dropout if n_layers > 1 else 0.0)\n",
    "        self.fc1 = nn.Linear(hidden_dim * 2, output_dim) if bidirectional else nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        if initialize: self.init_weights(initrange)\n",
    "\n",
    "    def init_hidden(self, bs):\n",
    "        weights = next(self.parameters())\n",
    "        hidden_dim, n_layers = self.rnn.hidden_size, self.rnn.num_layers\n",
    "        directions = 2 if self.rnn.bidirectional else 1\n",
    "\n",
    "        hidden = weights.new_zeros(directions * n_layers, bs, hidden_dim)\n",
    "        cell = weights.new_zeros(directions * n_layers, bs, hidden_dim)\n",
    "        return hidden, cell\n",
    "\n",
    "    def init_weights(self, initrange=0.1):\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc1.bias.data.zero_()\n",
    "        self.fc1.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs, msl = x.shape\n",
    "\n",
    "        hidden, cell = self.init_hidden(bs)\n",
    "        out = self.embedding(x)\n",
    "        out, (hidden, cell) = self.rnn(out, (hidden, cell))\n",
    "\n",
    "        if self.rnn.bidirectional:\n",
    "            out = torch.cat([hidden[-2], hidden[-1]], 1)\n",
    "        else: out = hidden[-1]\n",
    "\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "laciGuWqeYl9"
   },
   "source": [
    "Produce a setup, and use a scheduler this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "C2XHS_E4WyX7",
    "outputId": "fbdaf1a3-c4f6-47ba-eb89-73de7e643ac5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 5,846,834 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "model = LSTMClassifier(vocab_sz=len(vocab_set), \n",
    "                       embedding_dim=100, \n",
    "                       hidden_dim=128, \n",
    "                       output_dim=2, \n",
    "                       dropout=0.5,\n",
    "                       bidirectional=True,\n",
    "                       n_layers=1,\n",
    "                       initialize=True).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "epochs = 10\n",
    "iters = epochs * len(train_loader)\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=iters, eta_min=0)\n",
    "\n",
    "print(\"The model has {:,} trainable parameters\".format(count_parameters(model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c7GTxvtxeay9"
   },
   "source": [
    "Train with the same settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "id": "_0TUQcyMWyrg",
    "outputId": "7dd08b20-5d37-4f84-f6f3-09368a824f42"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:08<00:00, 61.98it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 162.66it/s]\n",
      "  1%|▏         | 7/547 [00:00<00:08, 62.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   1 | Train Loss 0.6602 | Train Acc 0.5795 | Valid Loss 0.5201 | Valid Acc 0.7679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:08<00:00, 61.99it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 161.73it/s]\n",
      "  1%|▏         | 7/547 [00:00<00:08, 61.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   2 | Train Loss 0.3998 | Train Acc 0.8390 | Valid Loss 0.4493 | Valid Acc 0.8288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:08<00:00, 61.79it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 162.57it/s]\n",
      "  1%|▏         | 7/547 [00:00<00:08, 61.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   3 | Train Loss 0.2511 | Train Acc 0.9119 | Valid Loss 0.3825 | Valid Acc 0.8529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:08<00:00, 61.80it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 162.72it/s]\n",
      "  1%|▏         | 7/547 [00:00<00:08, 60.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   4 | Train Loss 0.1579 | Train Acc 0.9484 | Valid Loss 0.3711 | Valid Acc 0.8537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:08<00:00, 62.04it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 164.98it/s]\n",
      "  1%|▏         | 7/547 [00:00<00:08, 62.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   5 | Train Loss 0.1043 | Train Acc 0.9695 | Valid Loss 0.4327 | Valid Acc 0.8590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:08<00:00, 61.36it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 164.16it/s]\n",
      "  1%|▏         | 7/547 [00:00<00:08, 63.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   6 | Train Loss 0.0678 | Train Acc 0.9807 | Valid Loss 0.5448 | Valid Acc 0.8555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:08<00:00, 60.93it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 162.18it/s]\n",
      "  1%|▏         | 7/547 [00:00<00:08, 62.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   7 | Train Loss 0.0455 | Train Acc 0.9887 | Valid Loss 0.6626 | Valid Acc 0.8375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:08<00:00, 61.39it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 165.22it/s]\n",
      "  1%|▏         | 7/547 [00:00<00:08, 60.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   8 | Train Loss 0.0335 | Train Acc 0.9923 | Valid Loss 0.6389 | Valid Acc 0.8516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:08<00:00, 61.65it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 161.51it/s]\n",
      "  1%|▏         | 7/547 [00:00<00:08, 62.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   9 | Train Loss 0.0285 | Train Acc 0.9939 | Valid Loss 0.6346 | Valid Acc 0.8516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:08<00:00, 61.66it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 161.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  10 | Train Loss 0.0264 | Train Acc 0.9942 | Valid Loss 0.6291 | Valid Acc 0.8507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "clip = 1.0\n",
    "train_losses, valid_losses = [], []\n",
    "\n",
    "for e in range(1, epochs + 1):\n",
    "    train_loss, train_acc = 0, 0\n",
    "    \n",
    "    model.train()\n",
    "    for x, y in tqdm(train_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_acc += accuracy(out, y)\n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc /= len(train_loader)\n",
    "\n",
    "    valid_loss, valid_acc = 0, 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(valid_loader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "            valid_acc += accuracy(out, y)\n",
    "    valid_loss /= len(valid_loader)\n",
    "    valid_acc /= len(valid_loader)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "    print(\"\\nEpoch {:3} | Train Loss {:.4f} | Train Acc {:.4f} | Valid Loss {:.4f} | Valid Acc {:.4f}\".format(e, train_loss, train_acc, valid_loss, valid_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wRl3UT3UeclF"
   },
   "source": [
    "This model has too much capacity, which caused it to overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "Jt_k9aWiWy-n",
    "outputId": "e943a174-b4d0-4d34-e8c5-ada480d19084"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8c9f705278>"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(data={'train': train_losses, 'valid': valid_losses}).plot.line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wks2PTmsefUe"
   },
   "source": [
    "To solve this, we'll look at a couple techniques we can use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d1nfcM9wHy28"
   },
   "source": [
    "# RNN Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S0ZCpvqHeijF"
   },
   "source": [
    "In this section, we'll introduce special flavors of dropout used specifically for RNNs. We'll use the functional package from PyTorch to facilitate some intermediate computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NlUO7Kl-FvYR"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3sPtzXc9epfL"
   },
   "source": [
    "We'll write code for producing *dropout masks*, which will be multiplied to our matrices to zero out certain weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0tMzgb8GH3bD"
   },
   "outputs": [],
   "source": [
    "# Credits to the contributors at fast.ai\n",
    "def dropout_mask(x, sz, p):\n",
    "    return x.new(*sz).bernoulli_(1-p).div_(1-p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zOyhphMkeu0p"
   },
   "source": [
    "We'll write a special dropout for RNN layers. This ensures that we consistently zero-out across a time-dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "omrG26BNH4mq"
   },
   "outputs": [],
   "source": [
    "class RNNDropout(nn.Module):\n",
    "    def __init__(self, p=0.5):\n",
    "        super().__init__()\n",
    "        self.p=p\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not self.training or self.p == 0.: \n",
    "            return x\n",
    "        m = dropout_mask(x.data, (x.size(0), 1, x.size(2)), self.p)\n",
    "        return x * m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sfi08q71e922"
   },
   "source": [
    "We'll also introduce a variant of dropout for the embedding layer. This wraps around an existing embedding layer and zero out certain embedding weights during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_SolpWZSH6ID"
   },
   "outputs": [],
   "source": [
    "class EmbeddingDropout(nn.Module):\n",
    "    def __init__(self, emb, embed_p):\n",
    "        super(EmbeddingDropout, self).__init__()\n",
    "        self.emb = emb\n",
    "        self.embed_p = embed_p\n",
    "        self.pad_idx = self.emb.padding_idx\n",
    "        if self.pad_idx is None: self.pad_idx = -1\n",
    "\n",
    "    def forward(self, words, scale=None):\n",
    "        if self.training and self.embed_p != 0:\n",
    "            size = (self.emb.weight.size(0),1)\n",
    "            mask = dropout_mask(self.emb.weight.data, size, self.embed_p)\n",
    "            masked_embed = (self.emb.weight * mask)\n",
    "        else: \n",
    "            masked_embed = (self.emb.weight)\n",
    "        if scale: \n",
    "            masked_embed.mul_(scale)\n",
    "        out = F.embedding(words, masked_embed, self.pad_idx, self.emb.max_norm,\n",
    "                          self.emb.norm_type, self.emb.scale_grad_by_freq, self.emb.sparse)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCs1YHPLfCs8"
   },
   "source": [
    "Our final classifier now looks like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hH_1AYEdH8ZZ"
   },
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_sz, embedding_dim, hidden_dim, output_dim, bidirectional=False, \n",
    "                 n_layers=1, dropout=0.5, recur_dropout=0.3, embed_dropout=0.1, initrange=0.1, initialize=True):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_sz, embedding_dim)\n",
    "        self.embedding_dp = EmbeddingDropout(self.embedding, embed_dropout)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, \n",
    "                           bidirectional=bidirectional, num_layers=n_layers, \n",
    "                           dropout=recur_dropout if n_layers > 1 else 0.0)\n",
    "        self.fc1 = nn.Linear(hidden_dim * 2, output_dim) if bidirectional else nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.rnn_dropout = RNNDropout(recur_dropout)\n",
    "\n",
    "        if initialize: self.init_weights(initrange)\n",
    "\n",
    "    def init_hidden(self, bs):\n",
    "        weights = next(self.parameters())\n",
    "        hidden_dim, n_layers = self.rnn.hidden_size, self.rnn.num_layers\n",
    "        directions = 2 if self.rnn.bidirectional else 1\n",
    "\n",
    "        hidden = weights.new_zeros(directions * n_layers, bs, hidden_dim)\n",
    "        cell = weights.new_zeros(directions * n_layers, bs, hidden_dim)\n",
    "        return hidden, cell\n",
    "\n",
    "    def init_weights(self, initrange=0.1):\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc1.bias.data.zero_()\n",
    "        self.fc1.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs, msl = x.shape\n",
    "\n",
    "        hidden, cell = self.init_hidden(bs)\n",
    "        out = self.embedding_dp(x)\n",
    "        out = self.rnn_dropout(out)\n",
    "        out, (hidden, cell) = self.rnn(out, (hidden, cell))\n",
    "\n",
    "        if self.rnn.bidirectional:\n",
    "            out = torch.cat([hidden[-2], hidden[-1]], 1)\n",
    "        else: out = hidden[-1]\n",
    "\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iyqkyG4ofRxY"
   },
   "source": [
    "We'll instantiate our model. This time, we'll use AMSGrad as our optimizer, and introduce weight decay (L2 regularization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ztklABgKIef8",
    "outputId": "cf447789-8b71-4069-b40b-cbed27a9bdf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 5,846,834 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "model = LSTMClassifier(vocab_sz=len(vocab_set), \n",
    "                       embedding_dim=100, \n",
    "                       hidden_dim=128, \n",
    "                       output_dim=2, \n",
    "                       dropout=0.65,\n",
    "                       embed_dropout=0.1,\n",
    "                       recur_dropout=0.65,\n",
    "                       bidirectional=True,\n",
    "                       n_layers=1,\n",
    "                       initialize=True).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-2, amsgrad=True)\n",
    "\n",
    "epochs = 10\n",
    "iters = epochs * len(train_loader)\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=iters, eta_min=0)\n",
    "\n",
    "print(\"The model has {:,} trainable parameters\".format(count_parameters(model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q7-XKFQAfaFf"
   },
   "source": [
    "Train with the same settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "id": "a2ah6cPWIlIq",
    "outputId": "7cbb2a1f-d2a4-4259-bf0b-7cadc00f43be"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:08<00:00, 61.49it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 153.98it/s]\n",
      "  1%|          | 6/547 [00:00<00:09, 59.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   1 | Train Loss 0.6939 | Train Acc 0.5012 | Valid Loss 0.6908 | Valid Acc 0.5339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:08<00:00, 60.99it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 157.07it/s]\n",
      "  1%|          | 6/547 [00:00<00:09, 57.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   2 | Train Loss 0.6138 | Train Acc 0.6642 | Valid Loss 0.5327 | Valid Acc 0.7523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:09<00:00, 59.32it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 153.75it/s]\n",
      "  1%|          | 6/547 [00:00<00:09, 58.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   3 | Train Loss 0.4631 | Train Acc 0.7962 | Valid Loss 0.3848 | Valid Acc 0.8344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:09<00:00, 59.16it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 156.34it/s]\n",
      "  1%|          | 6/547 [00:00<00:09, 58.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   4 | Train Loss 0.3817 | Train Acc 0.8424 | Valid Loss 0.3390 | Valid Acc 0.8602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:09<00:00, 60.08it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 152.94it/s]\n",
      "  1%|          | 6/547 [00:00<00:09, 59.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   5 | Train Loss 0.3293 | Train Acc 0.8703 | Valid Loss 0.3469 | Valid Acc 0.8535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:09<00:00, 58.74it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 164.08it/s]\n",
      "  1%|          | 6/547 [00:00<00:09, 59.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   6 | Train Loss 0.2974 | Train Acc 0.8841 | Valid Loss 0.3354 | Valid Acc 0.8683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:09<00:00, 59.78it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 162.54it/s]\n",
      "  1%|▏         | 7/547 [00:00<00:08, 60.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   7 | Train Loss 0.2712 | Train Acc 0.8964 | Valid Loss 0.3334 | Valid Acc 0.8657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:09<00:00, 58.44it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 156.17it/s]\n",
      "  1%|          | 6/547 [00:00<00:09, 58.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   8 | Train Loss 0.2620 | Train Acc 0.9003 | Valid Loss 0.3374 | Valid Acc 0.8652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:09<00:00, 59.10it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 158.92it/s]\n",
      "  1%|          | 6/547 [00:00<00:09, 59.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   9 | Train Loss 0.2547 | Train Acc 0.9024 | Valid Loss 0.3398 | Valid Acc 0.8655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:09<00:00, 59.57it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 160.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  10 | Train Loss 0.2469 | Train Acc 0.9053 | Valid Loss 0.3368 | Valid Acc 0.8671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "clip = 1.0\n",
    "train_losses, valid_losses = [], []\n",
    "\n",
    "for e in range(1, epochs + 1):\n",
    "    train_loss, train_acc = 0, 0\n",
    "    \n",
    "    model.train()\n",
    "    for x, y in tqdm(train_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_acc += accuracy(out, y)\n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc /= len(train_loader)\n",
    "\n",
    "    valid_loss, valid_acc = 0, 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(valid_loader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "            valid_acc += accuracy(out, y)\n",
    "    valid_loss /= len(valid_loader)\n",
    "    valid_acc /= len(valid_loader)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "    print(\"\\nEpoch {:3} | Train Loss {:.4f} | Train Acc {:.4f} | Valid Loss {:.4f} | Valid Acc {:.4f}\".format(e, train_loss, train_acc, valid_loss, valid_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eo8XJ-UlfcOD"
   },
   "source": [
    "This time, we get better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "4WEdEbVqImp8",
    "outputId": "68f6cccd-9135-45dc-fac1-9a21ecb32e45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8c9b722ba8>"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(data={'train': train_losses, 'valid': valid_losses}).plot.line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "15x9aB3mfeAN"
   },
   "source": [
    "The problem with randomly-initialized embeddings is that the model spends a lot of time moving the embeddings to the correct places, before it learns to solve the task it is trying to learn. This makes learning unwieldy.\n",
    "\n",
    "A solution to this is to use pretrained embeddings, which already contain syntactic information. This way, the model doesn't have to spend too much time adjusting, and training becomes smoother."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ydxhxJeWLWEh"
   },
   "source": [
    "# Pretrained Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j4YpJFMlfwyF"
   },
   "source": [
    "Let's download some pretrained GloVe embeddings.\n",
    "\n",
    "GloVe is a method of training embeddings that uses corpus-wide co-occurence data to assign positions to each word. We'll discuss and implement this ourselves in a future lesson. For now, we'll use pretrained ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xSFMtsEKJBtk"
   },
   "outputs": [],
   "source": [
    "#!wget https://s3.us-east-2.amazonaws.com/blaisecruz.com/embeddings/glove.6B.50d.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OL3Tb1Prf87h"
   },
   "source": [
    "We'll load the vectors into a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bQmtDa0YLy8Y"
   },
   "outputs": [],
   "source": [
    "with open('glove.6B.50d.txt', 'r') as f:\n",
    "    glove = {}\n",
    "    for line in f:\n",
    "        l = line.strip().split()\n",
    "        glove[l[0]] = [float(v) for v in l[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VqDV9u1ff-10"
   },
   "source": [
    "Here's the vectors for the word 'the'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "keyRiss9L9K2",
    "outputId": "8d11e646-6cc8-46b0-a335-b43b2eb46203"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.418, 0.24968, -0.41242, 0.1217, 0.34527, -0.044457, -0.49688, -0.17862, -0.00066023, -0.6566, 0.27843, -0.14767, -0.55677, 0.14658, -0.0095095, 0.011658, 0.10204, -0.12792, -0.8443, -0.12181, -0.016801, -0.33279, -0.1552, -0.23131, -0.19181, -1.8823, -0.76746, 0.099051, -0.42125, -0.19526, 4.0071, -0.18594, -0.52287, -0.31681, 0.00059213, 0.0074449, 0.17778, -0.15897, 0.012041, -0.054223, -0.29871, -0.15749, -0.34758, -0.045637, -0.44251, 0.18785, 0.0027849, -0.18411, -0.11514, -0.78581]\n"
     ]
    }
   ],
   "source": [
    "print(glove['the'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SFVDdKexgA3l"
   },
   "source": [
    "Let's use the vectors.\n",
    "\n",
    "For every word in our vocabulary that exists in the vocabulary of GloVe, we'll use the trained embedding. Otherwise, we'll use a randomly initialized one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wNZvYcn9L-QH"
   },
   "outputs": [],
   "source": [
    "glove_vocab = set(glove.keys())\n",
    "\n",
    "vectors = []\n",
    "for token in idx2word:\n",
    "    if token in glove_vocab: vectors.append(torch.FloatTensor(glove[token]))\n",
    "    else: vectors.append(torch.rand(50).uniform_(-0.1, 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_6_BgQyBgH5Q"
   },
   "source": [
    "Here's an example word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "colab_type": "code",
    "id": "5GQfZ1MPNU_R",
    "outputId": "0a42c39c-d869-42b6-e13f-193c0cee1d11"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'exacerbate'"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2word[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ul9LlK1ogJX1"
   },
   "source": [
    "And it's embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "T3JY3BdjNZv4",
    "outputId": "6b8c7044-0017-404e-b0bd-12628a0fe578"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41817, -0.46122, 0.010667, -0.12624, -0.87323, 0.63934, 1.39, 0.426, -0.016501, -0.28983, 0.31326, 0.035407, -0.21225, -0.52607, 0.2903, 1.5516, 0.20275, -0.69439, 1.142, 0.014968, -0.32994, -0.95339, -0.012949, 0.33271, 0.17152, -0.12719, 0.28879, 0.1482, 1.3775, 1.2105, 0.8042, 1.1108, 0.41383, -0.77357, -0.73544, 0.11489, -1.1682, -0.96491, 0.167, 0.23047, -1.0953, 0.22614, 0.21805, 0.00060762, 0.55483, 0.48155, 0.76849, 0.82595, -0.18012, 0.17437]\n"
     ]
    }
   ],
   "source": [
    "print(glove['exacerbate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j62SKJjfgLP_"
   },
   "source": [
    "Here's a sanity check to show that we copied it in the same index in the final vector matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "mksIQYIMNbEB",
    "outputId": "0549e4d0-c697-4031-eb35-dce7b993eabc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4.1817e-01, -4.6122e-01,  1.0667e-02, -1.2624e-01, -8.7323e-01,\n",
      "         6.3934e-01,  1.3900e+00,  4.2600e-01, -1.6501e-02, -2.8983e-01,\n",
      "         3.1326e-01,  3.5407e-02, -2.1225e-01, -5.2607e-01,  2.9030e-01,\n",
      "         1.5516e+00,  2.0275e-01, -6.9439e-01,  1.1420e+00,  1.4968e-02,\n",
      "        -3.2994e-01, -9.5339e-01, -1.2949e-02,  3.3271e-01,  1.7152e-01,\n",
      "        -1.2719e-01,  2.8879e-01,  1.4820e-01,  1.3775e+00,  1.2105e+00,\n",
      "         8.0420e-01,  1.1108e+00,  4.1383e-01, -7.7357e-01, -7.3544e-01,\n",
      "         1.1489e-01, -1.1682e+00, -9.6491e-01,  1.6700e-01,  2.3047e-01,\n",
      "        -1.0953e+00,  2.2614e-01,  2.1805e-01,  6.0762e-04,  5.5483e-01,\n",
      "         4.8155e-01,  7.6849e-01,  8.2595e-01, -1.8012e-01,  1.7437e-01])\n"
     ]
    }
   ],
   "source": [
    "print(vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cfjMceRygRQM"
   },
   "source": [
    "Finally, we'll turn this into a PyTorch tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "86_uBB0zN3iB",
    "outputId": "28c74608-77a1-42f5-bb43-1f8ecd32a051"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([56108, 50])\n"
     ]
    }
   ],
   "source": [
    "pretrained_embeddings = torch.stack(vectors)\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cciDMBxlPen8"
   },
   "source": [
    "# Putting Everything Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a6GLqmcegUMm"
   },
   "source": [
    "Let's put everything together. Instantiate a model with less regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K-KZZkDVOHJR"
   },
   "outputs": [],
   "source": [
    "model = LSTMClassifier(vocab_sz=len(vocab_set), \n",
    "                       embedding_dim=50, \n",
    "                       hidden_dim=256, \n",
    "                       output_dim=2, \n",
    "                       dropout=0.5,\n",
    "                       embed_dropout=0.1,\n",
    "                       recur_dropout=0.4,\n",
    "                       bidirectional=True,\n",
    "                       n_layers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lFY1Dr1WgYfI"
   },
   "source": [
    "We'll copy the vectors into our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yBidWhaBPnb_"
   },
   "outputs": [],
   "source": [
    "model.embedding_dp.emb.weight.data.copy_(pretrained_embeddings);\n",
    "model.embedding_dp.emb.weight.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X96N3YLogaec"
   },
   "source": [
    "And instantiate our setup. This time we'll train for a bit longer (20 epochs) and we won't use weight decay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "I_VFbTWjOPDy",
    "outputId": "8bdf185a-e012-43f6-f566-4bd765183a3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 3,437,210 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4, amsgrad=True)\n",
    "\n",
    "epochs = 20\n",
    "iters = epochs * len(train_loader)\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=iters, eta_min=0)\n",
    "\n",
    "print(\"The model has {:,} trainable parameters\".format(count_parameters(model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SL4fq4X1gfea"
   },
   "source": [
    "And train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Ag5XFZpEPCm6",
    "outputId": "9d641463-274e-4546-de14-0ec143b7cedd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:12<00:00, 42.47it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 140.38it/s]\n",
      "  1%|          | 5/547 [00:00<00:12, 43.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   1 | Train Loss 0.6779 | Train Acc 0.5703 | Valid Loss 0.6167 | Valid Acc 0.6770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:12<00:00, 42.11it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 137.02it/s]\n",
      "  1%|          | 5/547 [00:00<00:12, 42.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   2 | Train Loss 0.6468 | Train Acc 0.6390 | Valid Loss 0.5984 | Valid Acc 0.7064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:12<00:00, 42.26it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 139.05it/s]\n",
      "  1%|          | 5/547 [00:00<00:13, 41.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   3 | Train Loss 0.6191 | Train Acc 0.6662 | Valid Loss 0.5992 | Valid Acc 0.6798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:12<00:00, 42.34it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 141.35it/s]\n",
      "  1%|          | 5/547 [00:00<00:12, 43.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   4 | Train Loss 0.5876 | Train Acc 0.6942 | Valid Loss 0.6085 | Valid Acc 0.7261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:13<00:00, 41.98it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 137.40it/s]\n",
      "  1%|          | 5/547 [00:00<00:13, 41.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   5 | Train Loss 0.5402 | Train Acc 0.7392 | Valid Loss 0.4865 | Valid Acc 0.7691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:12<00:00, 42.19it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 138.79it/s]\n",
      "  1%|          | 5/547 [00:00<00:12, 43.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   6 | Train Loss 0.5113 | Train Acc 0.7613 | Valid Loss 0.4537 | Valid Acc 0.7990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:13<00:00, 42.02it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 136.11it/s]\n",
      "  1%|          | 5/547 [00:00<00:12, 41.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   7 | Train Loss 0.4732 | Train Acc 0.7818 | Valid Loss 0.4389 | Valid Acc 0.8119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:13<00:00, 41.99it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 139.35it/s]\n",
      "  1%|          | 5/547 [00:00<00:12, 42.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   8 | Train Loss 0.4510 | Train Acc 0.7941 | Valid Loss 0.4494 | Valid Acc 0.8102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:13<00:00, 41.89it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 137.97it/s]\n",
      "  1%|          | 5/547 [00:00<00:12, 42.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch   9 | Train Loss 0.4392 | Train Acc 0.8062 | Valid Loss 0.4125 | Valid Acc 0.8070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:13<00:00, 41.86it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 139.14it/s]\n",
      "  1%|          | 5/547 [00:00<00:13, 41.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  10 | Train Loss 0.4181 | Train Acc 0.8145 | Valid Loss 0.4623 | Valid Acc 0.7969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:12<00:00, 42.11it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 141.05it/s]\n",
      "  1%|          | 5/547 [00:00<00:12, 42.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  11 | Train Loss 0.4109 | Train Acc 0.8192 | Valid Loss 0.3766 | Valid Acc 0.8342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:12<00:00, 42.20it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 134.56it/s]\n",
      "  1%|          | 5/547 [00:00<00:12, 42.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  12 | Train Loss 0.4015 | Train Acc 0.8218 | Valid Loss 0.3827 | Valid Acc 0.8270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:13<00:00, 42.04it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 139.22it/s]\n",
      "  1%|          | 5/547 [00:00<00:12, 43.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  13 | Train Loss 0.3945 | Train Acc 0.8255 | Valid Loss 0.3850 | Valid Acc 0.8407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:13<00:00, 42.05it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 138.91it/s]\n",
      "  1%|          | 5/547 [00:00<00:12, 43.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  14 | Train Loss 0.3853 | Train Acc 0.8306 | Valid Loss 0.3949 | Valid Acc 0.8349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:12<00:00, 42.28it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 139.23it/s]\n",
      "  1%|          | 5/547 [00:00<00:13, 41.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  15 | Train Loss 0.3746 | Train Acc 0.8340 | Valid Loss 0.3681 | Valid Acc 0.8434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:13<00:00, 42.06it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 138.13it/s]\n",
      "  1%|          | 5/547 [00:00<00:12, 42.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  16 | Train Loss 0.3756 | Train Acc 0.8369 | Valid Loss 0.3730 | Valid Acc 0.8367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:12<00:00, 42.54it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 143.62it/s]\n",
      "  1%|          | 5/547 [00:00<00:12, 42.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  17 | Train Loss 0.3772 | Train Acc 0.8379 | Valid Loss 0.3865 | Valid Acc 0.8385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:13<00:00, 41.89it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 140.62it/s]\n",
      "  1%|          | 5/547 [00:00<00:12, 42.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  18 | Train Loss 0.3728 | Train Acc 0.8374 | Valid Loss 0.3785 | Valid Acc 0.8410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:13<00:00, 42.02it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 138.48it/s]\n",
      "  1%|          | 5/547 [00:00<00:12, 43.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  19 | Train Loss 0.3715 | Train Acc 0.8398 | Valid Loss 0.3777 | Valid Acc 0.8405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 547/547 [00:12<00:00, 42.30it/s]\n",
      "100%|██████████| 235/235 [00:01<00:00, 138.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch  20 | Train Loss 0.3732 | Train Acc 0.8389 | Valid Loss 0.3785 | Valid Acc 0.8397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "clip = 1.0\n",
    "train_losses, valid_losses = [], []\n",
    "\n",
    "for e in range(1, epochs + 1):\n",
    "    train_loss, train_acc = 0, 0\n",
    "    \n",
    "    model.train()\n",
    "    for x, y in tqdm(train_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_acc += accuracy(out, y)\n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc /= len(train_loader)\n",
    "\n",
    "    valid_loss, valid_acc = 0, 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(valid_loader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "            valid_acc += accuracy(out, y)\n",
    "    valid_loss /= len(valid_loader)\n",
    "    valid_acc /= len(valid_loader)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "    print(\"\\nEpoch {:3} | Train Loss {:.4f} | Train Acc {:.4f} | Valid Loss {:.4f} | Valid Acc {:.4f}\".format(e, train_loss, train_acc, valid_loss, valid_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z32U7QsfghQY"
   },
   "source": [
    "This leads to more robust training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "mxbJ-URWUyca",
    "outputId": "f4e4f49e-205b-46c8-974e-dc2f448b22d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8c9b70d940>"
      ]
     },
     "execution_count": 78,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(data={'train': train_losses, 'valid': valid_losses}).plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_x2dNBRXZ_Vr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "07b - RNN Sentiment Classification",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
